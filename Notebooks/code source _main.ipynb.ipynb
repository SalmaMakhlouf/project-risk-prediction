{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des bibliothèques \n",
    "\n",
    "#Le module \"rcParams\" est utilisé pour configurer les paramètres de rendu dans Matplotlib, tels que les tailles de police, les couleurs par défaut, etc.\n",
    "#%matplotlib inline :  spécifique à Jupyter Notebook . Cette directive indique à Jupyter d'afficher les graphiques générés par Matplotlib directement dans le notebook, plutôt que dans une fenêtre séparée. \n",
    "#NumPy : Une bibliothèque Python essentielle pour les calculs scientifiques\n",
    "#Pandas : Une bibliothèque Python puissante pour la manipulation et l'analyse de données, offrant des structures de données flexibles (Series et DataFrame) pour importer, nettoyer, transformer et analyser des jeux de données de manière efficace.\n",
    "#Seaborn : Une bibliothèque de visualisation de données basée sur Matplotlib\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation et affichage de jeu de données \n",
    "df = pd.read_excel(r'C:\\Users\\SALMA\\Downloads\\DATASET.xlsm')\n",
    "df\n",
    "# Public placeholder – change locally\n",
    "DATA_PATH = \"data/your_file.csv\"   # <- à remplacer en local\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df.to_csv('Prediction.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace commas with periods in the concerned columns \n",
    "df[['irr', 'Yield Index', 'IRR @ SELL', 'Gross Margin @ Mature Year']] = \\\n",
    "    df[['irr', 'Yield Index', 'IRR @ SELL', 'Gross Margin @ Mature Year']].replace(',', '.', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of the lines to delete\n",
    "indices_a_supprimer = df2[df2['project_type'].isin(['Type_A', 'Type_B', 'Type_C', 'Type_D','Type_E'])].index\n",
    "# Delete rows with found clues\n",
    "df2 = df2.drop(indices_a_supprimer)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines where 'Cost Bucket' equals 'Yes'\n",
    "df2 = df2[df2['Cost bucket'] != 'Yes']\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.nature.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Pandas \"apply\" function to apply a function to each element in the \"nature\" column\n",
    "def transform_nature(nature):\n",
    "    if nature == 'Project':\n",
    "        return 'Project'\n",
    "    else:\n",
    "        return 'Agile'\n",
    "\n",
    "df2['nature'] = df2['nature'].apply(transform_nature)\n",
    "\n",
    "# Afficher le résultat\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the specific columns we want to keep\n",
    "df2 = df2.loc[:, ['project_id','portfolio_level_1','Pportfolio_level_2','Budget Prior', 'project_type', 'nature','irr','Framework', 'status',\n",
    "'stage_OPEN','stage_CLOSE','stage_SELL','stage_ENGAGE','stage_DO','stage_SELECT','stage_IMPLEMENT','stage_PRODUCE','Program Holder','Program ID', 'Horizon', 'Business Case Id'\n",
    ",'Budget Total','Budget Total+CAPEX','Target Y+1','Total Costs + CAPEX','Costs Total']]\n",
    "\n",
    "# Remove all other columns\n",
    "df2 = df2.drop(columns=[col for col in df2.columns if col not in ['project_id','portfolio_level_1','portfolio_level_2','Budget Prior','Type', \n",
    "'nature','irr', 'Framework','Program ID', 'status','stage_OPEN','stage_CLOSE','stage_SELL','stage_ENGAGE','stage_DO','stage_SELECT','stage_IMPLEMENT','stage_PRODUCE','Program Holder', 'Horizon',\n",
    "'Business Case Id','Budget Total','Budget Total+CAPEX','Target Y+1','Total Costs + CAPEX','Costs Total']])\n",
    "\n",
    "# Afficher le résultat\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the specified columns in the list by removing white spaces and converting the values ​​to datetime objects in the format \"YYYY-MM-DD\".\n",
    "columns_to_transform = ['stage_OPEN','stage_CLOSE','stage_SELL','stage_ENGAGE','stage_DO','stage_SELECT','stage_IMPLEMENT','stage_PRODUCE']\n",
    "\n",
    "for col in columns_to_transform:\n",
    "    df2[col] = df2[col].str.strip()\n",
    "    df2[col] = pd.to_datetime(df2[col], format=\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['stage_OPEN','stage_CLOSE','stage_SELL','stage_ENGAGE','stage_DO','stage_SELECT','stage_IMPLEMENT','stage_PRODUCE']\n",
    "# calculate the duration for each row and store the results in a new column \"Project Duration\"\n",
    "df2['Project Duration'] = df2[date_columns].max(axis=1) - df2[date_columns].min(axis=1)\n",
    "df2['Project Duration'] = df2['Project Duration'].dt.days\n",
    "# Delete date columns\n",
    "df2 = df2.drop(columns=date_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the specific columns we want to keep\n",
    "indices_a_supprimer = df2[df2['status'].isin(['Frozen','Opened','Under Simulation', 'Planned'])].index\n",
    "# Remove all other columns\n",
    "df2 = df2.drop(indices_a_supprimer)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing or zero values ​​in \"Project Duration\" for each \"status\" value\n",
    "counts = df2.groupby('status')['Project Duration'].apply(lambda x: (x.isnull() | (x == 0)).sum())\n",
    "\n",
    "print(\"number of missing or zero values ​​in 'Project Duration' for each 'status' value:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values ​​in \"Project Duration\" for each \"status\" value\n",
    "missing_counts = df2.groupby('status')['Project Duration'].apply(lambda x: x.isnull().sum())\n",
    "\n",
    "# Count the number of zeros in \"Project Duration\" for each \"status\" value\n",
    "zero_counts = df2.groupby('status')['Project Duration'].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "print(\"number of missing or zero values ​​in 'Project Duration' for each 'status' value:\")\n",
    "print(missing_counts)\n",
    "print(\"\\nNumber of zeros in 'Project Duration' for each 'status' value:\")\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a value from the Horizon column and returns the corresponding value\n",
    "def get_horizon_value(Horizon):\n",
    "    if Horizon == 'H1 ':\n",
    "        return 0\n",
    "    elif Horizon == 'H3 ':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "# Apply the function to each item in the Horizon column to create a new \"Horizon Value\" column\n",
    "df2['Horizon'] = df2['Horizon'].apply(get_horizon_value)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définissez une fonction qui prend une valeur de la colonne Horizon et retourne la valeur correspondante\n",
    "def get_horizon_value(Framework):\n",
    "    if Framework == 'Waterfall':\n",
    "        return 0\n",
    "    elif Framework == 'Agile':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "# Appliquez la fonction à chaque élément de la colonne Horizon pour créer une nouvelle colonne \"Horizon Value\"\n",
    "df2['Framework'] = df2['Framework'].apply(get_horizon_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the “Project Size” column\n",
    "df2['Project Size'] = df2[['Budget Total','Budget Prior','Budget Total+CAPEX','Total Costs + CAPEX', 'Costs Total']].max(axis=1)\n",
    "\n",
    "# affichage du résultat\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2[\"status\"]==\"Cancelled\"].sort_values(\"Project Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2[\"Project Size\"]>500000][\"Project Size\"].hist(bins=100, figsize=(30, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation de la colonne 'Program ID'\n",
    "#Converts the values ​​in the 'Program ID' /Business Case Id' column to 1 if they are not empty, otherwise converts them to 0.\n",
    "df2['Program ID'] = df2['Program ID'].apply(lambda x: 1 if x.strip() != '' else 0)\n",
    "df2['Business Case Id'] = df2['Business Case Id'].apply(lambda x: 1 if x.strip() != '' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['project_id','portfolio_level_1','Pportfolio_level_2','Budget Prior', 'project_type', 'nature','irr','Framework', 'status',\n",
    "'Horizon', 'Business Case Id','Project Size','Project Duration']\n",
    "df3 = df2[cols_to_use].copy()\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Project Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and add canceled projects from CSV file extrated from df_snap (datatset rolling 12 month)\n",
    "cancelled_rows = pd.read_csv(r'C:\\Users\\SALMA\\Desktop\\python\\cancelled_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate rows from canceled_rows to DF2\n",
    "df5 = pd.concat([df3, cancelled_rows]).drop_duplicates(subset='ID')\n",
    "\n",
    "# Check count of 'Project Size' values ​​after adding\n",
    "print(df5['Project Size'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation function\n",
    "def strip_spaces(value):\n",
    "    return value.strip()\n",
    "\n",
    "# Apply the function to the \"Program Holder\" column\n",
    "df5['Program Holder'] = df5['Program Holder'].apply(strip_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select projects with a value of 0 in \"Project Size\" and a status \"Completed\"\n",
    "df_filtered = df5.loc[(df5['Project Size'] == 0) & (df5['status'] == 'Completed')]\n",
    "\n",
    "# Delete selected projects\n",
    "df5 = df5.drop(df_filtered.index)\n",
    "\n",
    "# Afficher le DataFrame mis à jour\n",
    "df5.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purpose : Project Size defines the project budget. We aimed to select the most relevant information from EOLE85. We discovered numerous 0 values in this column, so we transformed them into NaN values. \n",
    "# Additionally, we excluded some completed projects for which budget information was unavailable.\n",
    "# Liste des colonnes à remplacer\n",
    "colonnes_a_remplacer = ['Project Size']\n",
    "\n",
    "# Replace all 0 values ​​in column ['Project Size'] to be replaced with NaN\n",
    "for colonne in colonnes_a_remplacer:\n",
    "    df5[colonne] = df5[colonne].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2 = {'EM': 0, 'IA':1}\n",
    "mapping4 = {'Project': 0, 'Agile': 1}\n",
    "mapping5 = {'Completed': 1, 'Cancelled': 0}\n",
    "mapping7 = { 'yes':1 ,'no':0 }\n",
    "\n",
    "colonnes_mapping = {'portfolio_level_1': mapping2, 'nature': mapping4, 'status': mapping5 ,'Program Holder' :mapping7}\n",
    "\n",
    "for colonne, mapping in colonnes_mapping.items():\n",
    "    df5[colonne] = df5[colonne].replace(mapping)\n",
    "\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.drop('irr',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['Project Size'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy \"Project Duration\" column from df2 using ID as key\n",
    "df5['Project Duration'] = df5['ID'].map(df2.set_index('ID')['Project Duration'])\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for status, statusdf in df5.groupby(\"status\"):\n",
    "    print(status)\n",
    "    statusdf[\"Project Duration\"].hist(bins=100, figsize=(30, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5[\"Project Size sqrt\"] = df5[\"Project Size\"].apply(np.sqrt)\n",
    "#df5[\"Project Duration sqrt\"] = df5[\"Project Duration\"].apply(np.sqrt)\n",
    "#col=['Project Size','Project Duration']\n",
    "#df5 = df5.drop(col,axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'portfolio_level_1': 0.5 ,'portfolio_level_2': 1 , 'project_type': 1, 'nature': 0.5,\n",
    "           'Framework': 0.5, 'status': 0.5, 'Program Holder': 0.5, 'Program ID': 0.5,\n",
    "           'Horizon': 1, 'Business Case Id': 0.5 ,'Project Size' :1 }\n",
    "\n",
    "\n",
    "def weighted_distance(row1, row2, weights):\n",
    "    dist = 0\n",
    "    weight_sum = sum(weights.values())\n",
    "    \n",
    "    for col, weight in weights.items():\n",
    "        if row1[col] == row2[col]:\n",
    "            dist += weight\n",
    "    \n",
    "    normalized_dist = dist / weight_sum\n",
    "    return normalized_dist\n",
    "\n",
    "def impute_missing_values(row, col, df):\n",
    "    #Si la valeur de la cellule row[col] est manquante, nous procédons au traitement.\n",
    "    if pd.isnull(row[col]):\n",
    "        #num est une variable utilisée pour stocker la somme pondérée des valeurs non manquantes.\n",
    "        #den est une variable utilisée pour stocker la somme des proximités pondérées.\n",
    "        num = 0\n",
    "        den = 0\n",
    "\n",
    "        # Calcul de la somme pondérée des valeurs non manquantes\n",
    "        #Nous parcourons les autres lignes (other_row) du DataFrame df3 et calculons la proximité entre la ligne row et chaque autre ligne à l'aide de la fonction weighted_distance,\n",
    "        # en utilisant la formule de proximité : proximity = 1 / (weighted_distance(row, other_row, weights) + 0.01).\n",
    "        for _, other_row in df.iterrows():\n",
    "            #Si la valeur de la cellule other_row[col] n'est pas manquante :\n",
    "            if not pd.isnull(other_row[col]):\n",
    "                proximity = 1 / (weighted_distance(row, other_row, weights) + 0.01)\n",
    "                #nous mettons à jour num en ajoutant le produit de la proximité et de la valeur de la cellule 'other_row[col]'\n",
    "                # nous mettons à jour den en ajoutant simplement la proximité.\n",
    "                value = other_row[col]\n",
    "                num += proximity * value\n",
    "                den += proximity\n",
    "        #Si den n'est pas égal à zéro, cela signifie qu'il y a des valeurs non manquantes pour la colonne col et nous pouvons effectuer l'imputation.\n",
    "        if den != 0:\n",
    "            #Nous calculons la valeur interpolée en divisant num par den.\n",
    "            interpolated_value = num / den\n",
    "            #Nous remplaçons la valeur manquante dans la colonne col de la ligne row du DataFrame df3 par interpolated_value.\n",
    "            df.at[row.name, col] = interpolated_value\n",
    "            return interpolated_value\n",
    "    #Si la valeur de la cellule row[col] n'est pas manquante à l'origine, nous la renvoyons telle quelle sans la modifier.\n",
    "    return row[col]\n",
    "\n",
    "# Imputation pour les colonnes numériques\n",
    "for col in ['Project Duration']:\n",
    "    df5[col] = df5.apply(impute_missing_values, args=(col, df5), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(df5['status'])\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(df5['status']) * 100\n",
    "\tprint('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv('DF5_DF2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Cost Variation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load  the CSV file containing information about cost variations\n",
    "df_cost_variation_common = pd.read_csv(r'C:\\Users\\SALMA\\Desktop\\python\\df_cost_variation_common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Merge df5 with DF_variation using the ID column as the merge key\n",
    "df_commun = df5.merge(df_cost_variation_common, on='ID', how='left')\n",
    "\n",
    "# Affichage du jeu de données df5 avec les colonnes de variation ajoutées\n",
    "df_commun.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick check for missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that start with \"Expenses\", \"Internal\" and \"External\"\n",
    "columns_to_check = [col for col in df_commun.columns if col.startswith((\"Expenses\", \"Internal\", \"External\"))]\n",
    "\n",
    "# Count the number of projects with missing values ​​in all specified columns\n",
    "count_missing_all = df_commun[columns_to_check].isnull().all(axis=1).sum()\n",
    "\n",
    "print(\"Number of projects with missing values ​​in all specified columns:\", count_missing_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter projects with status 0 among projects with missing values ​​in all specified columns\n",
    "count_status_zero = df_commun[df_commun['status'] == 0][columns_to_check].isnull().all(axis=1).sum()\n",
    "\n",
    "print(\"Number of projects with missing values ​​in all columns and status equal to 0:\", count_status_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSelect the columns that start with \"Expenses\", \"Internal\" and \"External\"\n",
    "columns_to_check = [col for col in df_commun.columns if col.startswith((\"Expenses\", \"Internal\", \"External\"))]\n",
    "# Filter projects with status 0 among projects with missing values ​​in all specified columns:\n",
    "projects_status_zero = df_commun.loc[(df_commun['status'] == 0) & df_commun[columns_to_check].isnull().all(axis=1)]\n",
    "\n",
    "# Show selected projects\n",
    "print(\"Projects with missing values ​​in all columns and status equal to 0:\")\n",
    "print(projects_status_zero)\n",
    "\n",
    "# save the selected projects in another DataFrame (df_status_zero)\n",
    "df_status_zero = projects_status_zero.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_zero.to_csv('df_status_zero.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost_variation_Cancelled = pd.read_csv(r'C:\\Users\\SALMA\\Desktop\\python\\df_cost_variation_Cancelled.csv')\n",
    "df_cost_variation_Cancelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.update(df_cost_variation_Cancelled)\n",
    "df_commun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun= df_commun.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(df_commun['status'])\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(df_commun['status']) * 100\n",
    "\tprint('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avecID = df_commun.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_status_0 = df_commun.loc[df_commun['status'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['ID', 'portfolio_level_2']\n",
    "df_commun = df_commun.drop(col , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.Type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_1 = pd.get_dummies(df_commun['project_type'])\n",
    "df_commun = pd.concat([df_commun,dummies_1],axis=1)\n",
    "df_commun = df_commun.drop('Type',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphe rprésentant la corrélation entre les featutres deux à deux\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#data_f=df2.loc[1:,'status':'OPTIMIZE']\n",
    "corrdata=df_commun[['portfolio_level_1', 'nature', 'Framework', 'status',\n",
    "       'Program Holder', 'Program ID', 'Horizon', 'Business Case Id',\n",
    "       'Project Size', 'Project Duration', 'Expenses_amount_mean',\n",
    "       'Expenses_amount_max', 'Expenses_amount_min', 'Expenses_amount_std',\n",
    "       'Expenses_slope_mean', 'Expenses_slope_max', 'Expenses_slope_min',\n",
    "       'Expenses_slope_std', 'External Labor_amount_mean',\n",
    "       'External Labor_amount_max', 'External Labor_amount_min',\n",
    "       'External Labor_amount_std', 'External Labor_slope_mean',\n",
    "       'External Labor_slope_max', 'External Labor_slope_min',\n",
    "       'External Labor_slope_std', 'Internal Labor_amount_mean',\n",
    "       'Internal Labor_amount_max', 'Internal Labor_amount_min',\n",
    "       'Internal Labor_amount_std', 'Internal Labor_slope_mean',\n",
    "       'Internal Labor_slope_max', 'Internal Labor_slope_min',\n",
    "       'Internal Labor_slope_std', 'Type_A', 'Type_B', \n",
    "       'Type_C', 'Type_D', 'Type_E']]\n",
    "corr=corrdata.corr()\n",
    "plt.figure(figsize=(30,20))\n",
    "#sns.set_context(\"poster\")\n",
    "sns.heatmap(corr.abs(),annot=True, annot_kws={\"size\":10})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrer le dataframe pour les projets ayant Project Size = 142 et Project Duration = 1420\n",
    "filtered_projects = df_avecID.loc[(df_avecID['Project Size'] == 130265.0) & (df_avecID['Project Duration'] == 1491)]\n",
    "\n",
    "# Afficher les informations sur les projets filtrés\n",
    "filtered_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_commun), columns=df_commun.columns)\n",
    "\n",
    "# Afficher le DataFrame normalisé\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X, y \n",
    "#define x, y and x_test\n",
    "y = df_commun.status\n",
    "X = df_commun.drop('status', axis = 1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commun.loc[df_commun['status'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(df_commun.status)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(df_commun.status) * 100\n",
    "\tprint('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X, y, random_state=1, test_size=0.20, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier()\n",
    "# Instancier la classe SMOTE\n",
    "smote = SMOTE(random_state=0,sampling_strategy=0.75)\n",
    "\n",
    "# Appliquer la méthode fit_resample pour équilibrer les données d'entraînement\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entraîner le modèle sur les données équilibrées\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test  , y_pred)\n",
    "print('precision: ', precision)\n",
    "print('f1_score: ',f1)\n",
    "confusion_matrix(y_test  , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "make_confusion_matrix(cf_matrix, categories=[\"Cancelled\", \"Completed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Accuracy train: ',rfc.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=pd.DataFrame({'Actual': y_test, 'Predicted':y_pred})\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "     #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(rfc.feature_importances_,X_train.columns,'RANDOM FOREST')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST_SANS_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "pos_weight = len(y_train[y_train==1]) / len(y_train[y_train==0])\n",
    "\n",
    "\n",
    "XGBmodel = XGBClassifier(scale_pos_weight =pos_weight)\n",
    "XGBmodel.fit(X_train, y_train)\n",
    "xgbprediction = XGBmodel.predict(X_test)\n",
    "print('Accuracy of xgboost:', accuracy_score(xgbprediction,y_test))\n",
    "plot_importance(XGBmodel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report\n",
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test, xgbprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, xgbprediction)\n",
    "make_confusion_matrix(cf_matrix, categories=[\"Cancelled\", \"Completed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST_AVEC_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGBmode_SMOTE = XGBClassifier()\n",
    "# Instancier la classe SMOTE\n",
    "smote = SMOTE(random_state=0, sampling_strategy=0.74)\n",
    "\n",
    "# Appliquer la méthode fit_resample pour équilibrer les données d'entraînement\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entraîner le modèle sur les données équilibrées\n",
    "XGBmode_SMOTE.fit(X_resampled, y_resampled)\n",
    "\n",
    "xgbprediction2 = XGBmode_SMOTE.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "precision = precision_score(y_test, xgbprediction2)\n",
    "f1 = f1_score(y_test  , xgbprediction2)\n",
    "print('precision: ', precision)\n",
    "print('f1_score: ',f1)\n",
    "confusion_matrix(y_test  , xgbprediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, xgbprediction2)\n",
    "make_confusion_matrix(cf_matrix, categories=[\"Cancelled\", \"Completed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaboostclassifier = AdaBoostClassifier()\n",
    "# Instancier la classe SMOTE\n",
    "smote = SMOTE(random_state=0, sampling_strategy=0.8)\n",
    "\n",
    "# Appliquer la méthode fit_resample pour équilibrer les données d'entraînement\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Entraîner le modèle sur les données équilibrées\n",
    "adaboostclassifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "adaboostprediction = adaboostclassifier.predict(X_test)\n",
    "print('Accuracy of Ada Boost:', accuracy_score(adaboostprediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "precision = precision_score(y_test, adaboostprediction)\n",
    "f1 = f1_score(y_test  , adaboostprediction)\n",
    "print('precision: ', precision)\n",
    "print('f1_score: ',f1)\n",
    "confusion_matrix(y_test  , adaboostprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(XGBmode_SMOTE, open(\"pima.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = XGBmode_SMOTE.predict_proba(X_test)[:,1]\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=[[1,38,1,0,1,1]] #=1\n",
    "#data1=[[1,38,1,1,1,1]] #= 0\n",
    "input_data= []\n",
    "features=[.........]\n",
    "\n",
    "for i in features:\n",
    "  print(f'Donner  {i} :')\n",
    "  a=input()\n",
    "  input_data.append(float(a))\n",
    "print(input_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
